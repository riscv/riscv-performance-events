[[body]]
== Groups

A standard set of performance events and metrics are specified below.  The events and metric definition are organized into groups, many of which include a hierarchy of sub-events that constrain what is counted.

Some of the event groups include both speculative and non-speculative events.  In such groups, the event names are appended with one of the following.

* .RET - for non-speculative events counted at retirement.
* .SPEC - for speculative events, which may include events incurred by instructions that do not retire.

NOTE: _In general, RET events are more useful for performance analysis, since they are consistent with software's view of the instruction flow. But they can be significantly more expensive to implement, as they require event data to be staged along with the associated instruction to retirement. It is up to implementations to decide whether to support the RET, SPEC, or both variants of an event._

=== GENERAL Events

This group contains general events not specific to a particular part of CPU pipeline. 

include::adoc_event_tables/general.adoc[]

=== INST (Instruction) Events
:xrefstyle: short

This group contains events that count RISC-V instructions.  Each event in this group has both speculative (.SPEC) and non-speculative (.RET) versions, though only the non-speculative events are listed in the tables below.

INST events are broken down by instruction categories at the top level of the event hierarchy.  When no category is included in the event name (e.g., INST.RET), all instructions are counted.

.INST Event Categories
[cols="20%,80%"]
|===
| BRJMP | Branch and jump instructions.  Includes all BRANCH, JAL, and JALR opcodes, including compressed varieties.
| MISPRED | Branch and jump instructions that were mispredicted.
| LOAD | Memory load instructions.  Includes all instructions that perform memory read operations.
| STORE | Memory store instructions.  Includes all instructions that perform memory write operations.
| LDST | Memory load and store instructions.  Represents the union of the LOAD and STORE categories.
| MO | Memory ordering instructions.  Includes FENCE and FENCE.TSO instructions.
| INT | Integer computational instructions.  Includes all integer computational instructions from RVxI, including compressed varieties.  Also includes all computational instructions from the M extension and the A extension (AMO*).  Whether NOP instructions are counted is implementation-dependent.
| FP | Floating point instructions.  Includes all instructions from the F, D, Q, and Zfa extensions.
| RVV | Vector instructions.  Includes all instructions from the V extension.
| RVC | Compressed instructions.  Includes all instructions from the C extension.
|===

==== Control Transfer Instruction Events

The control transfer instruction categories, BRJMP and MISPRED, include additional levels of hierarchy that allow counting per transfer instruction type.  When no type is included in the event name (e.g., INST.BRJMP.RET), all types are counted.

.Control Transfer Event Types
[cols="20%,80%"]
|===
| BRANCH | Branch instructions.
| BRANCH.TK | Taken branch instructions.
| BRANCH.NT | Not-taken branch instructions.
| IND | Indirect (uninferrable) jump and call instructions.
| IND.CALL | Indirect (uninferrable) call instructions.
| IND.JUMP | Indirect (uninferrable) jump instructions without linkage.
| IND.LJUMP | Other indirect (uninferrable) jump instructions with linkage.
| DIR | Direct (inferrable) jump and call instructions.  Applies only for BRJMP, not MISPRED.
| DIR.CALL | Direct (inferrable) call instructions.  Applies only for BRJMP, not MISPRED.
| DIR.JUMP | Direct (inferrable) jump instructions without linkage.  Applies only for BRJMP, not MISPRED.
| DIR.LJUMP | Other direct (inferrable) jump instructions with linkage.  Applies only for BRJMP, not MISPRED.
| CORSWAP| Co-routine swap instructions.
| RETURN | Function return instructions.
| TK | Jump and taken branch instructions.
| PRED | Predicted branch and jump instructions.  Represents the union of BRANCH, IND, CORSWAP, and RETURN types above.  This is implicit for MISPRED, so applies only for BRJMP.
|===

With the exception of the TK and PRED types, all types listed above utilize the control transfer type definitions provided by the trace and Smctr/Ssctr specs.  For completeness, the definitions are replicated below.

.Control Transfer Type Definitions
[%unbreakable]
[cols="37%,63%", options="header",]
|===
| Transfer Type Name | Associated Opcodes
.3+| Indirect call | JALR _x1_, _rs_ where _rs_ != _x5_
| JALR _x5_, _rs_ where _rs_ != _x1_
| C.JALR _rs1_ where _rs1_ != _x5_
.4+| Direct call | JAL _x1_
| JAL _x5_
| C.JAL
| CM.JALT _index_
.2+| Indirect jump (without linkage) | JALR _x0_, _rs_ where _rs_ != (_x1_ or _x5_)
| C.JR _rs1_ where _rs1_ != (_x1_ or _x5_)
.3+| Direct jump (without linkage) | JAL _x0_
| C.J
| CM.JT _index_
.3+| Co-routine swap | JALR _x1_, _x5_
| JALR _x5_, _x1_
| C.JALR _x5_
.3+| Function return | JALR _rd_, _rs_ where _rs_ == (_x1_ or _x5_) and _rd_ != (_x1_ or _x5_)
| C.JR _rs1_ where _rs1_ == (_x1_ or _x5_)
| CM.POPRET(Z)
| Other indirect jump (with linkage) | JALR _rd_, _rs_ where _rs_ != (_x1_ or _x5_) and _rd_ != (_x0_, _x1_, or _x5_)
| Other direct jump (with linkage) | JAL _rd_ where _rd_ != (_x0_, _x1_, or _x5_)
|===

==== Memory Access Instruction Events

The memory access instruction categories, LOAD, STORE, and LDST, include additional levels of hierarchy that allow counting per data source, address source, or cacheability.  When no additional qualifier is included in the event name (e.g., INST.LOAD.RET), all types are counted.

.Memory Event Categories
[cols="20%,80%"]
|===
| UC | Instructions that perform a data access to an uncacheable region of memory.
| DSRC.* | Instructions that accessed data from the specified source (see <<dsrcs>>).
| ASRC.* | Instructions whose data address translation came from the specified source (see <<asrcs>>).
|===

.DSRC Event Data Sources
[[dsrcs]]
[cols="20%,80%"]
|===
| STLF | Load instructions to which data was forwarded by an older store.
| <cache> | Instructions for which the data access hit in the selected cache.  See cache naming standards in <<CACHE Events>>.
| <cache>.MISS | Instructions for which the data access missed in the selected cache.  See cache naming standards in <<CACHE Events>>.
| <cache>.MERGE | Instructions for which the data access merged with an outstanding miss in the selected cache.  See cache naming standards in <<CACHE Events>>.
| LOCAL.MEM | Instructions for which the data access hit in local memory.
| REMOTE.MEM | Instructions for which the data access hit in remote memory.
| REMOTE.CACHE | Instructions for which the data access hit in a remote cache.
| REMOTE.HITM | Instructions for which the data access hit modified data in a remote cache.
|===

NOTE: _Some instructions perform multiple memory accesses.  Because these events count instructions, the event should be incremented if any access performed by the associated instruction meets the event criteria._

NOTE: _What constitutes local vs remote above is left up to implementations.  It is expected that remote accesses incur significantly more latency than local accesses.  A straightforward approach may be for local to imply the same NUMA node, while remote implies a different NUMA node._

NOTE: _Implementations may execute some memory accesses post-retirement.  In such cases, even non-speculative (.RET) DRSC events may not be reflected in the counter immediately after the associated instruction retires._

.ASRC Event Translation Sources
[[asrcs]]
[cols="20%,80%"]
|===
| L__i__ | Instructions for which the data address translation hit in TLB level _i_.
| L__i__.MISS | Instructions for which the data address translation missed in TLB level _i_.
|===

As with CACHE events, the L1 TLB is the nearest TLB, while the LL (last level) TLB is the outermost TLB.

==== Vector Instruction Events

The RVV events include additional levels of hierarchy that allow counting per vector instruction type.  When no type is included in the event name (e.g., INST.RVV.RET), all types are counted.

.RVV Event Instruction Types
[cols="20%,80%"]
|===
| LOAD | Vector load instructions.
| STORE | Vector store instructions.
| LDST | Vector memory instructions, the union of the LOAD and STORE types.
| CFG | Vector configuration (VSET{I}VL{I}) instructions.
| ARITH | Vector arithmetic instructions.
| ARITH.INT | Vector arithmetic vector-integer instructions.
| ARITH.FP | Vector arithmetic vector-FP instructions.
|===

The LOAD, STORE, and LDST types include an additional level of hierarchy that allows counting per addressing mode.  When no addressing mode is included in the event name (e.g., INST.RVV.LOAD.RET), all modes are counted.

.RVV Memory Instruction Addressing Modes
[cols="20%,80%"]
|===
| UNIT | Vector unit-stride access instructions.
| IDXU | Vector indexed-unordered access instructions.
| STRD | Vector strided access instructions.
| IDXO | Vector indexed-ordered access instructions.
|===

==== INST Event and Metric Tables

include::adoc_event_tables/inst.adoc[]

FIXME: add inst_metrics table


=== CACHE Events
:xrefstyle: short

This group contains events and metrics for instruction, data, and unified caches.  Events in this group count accesses from the cache's perspective; if an instruction performs two cache accesses, they will be counted separately.  Further, all events in this group count speculative accesses.

The top level of the CACHE event hierarchy idenfies the cache associated with the event.  The standard cache naming scheme is detailed below.

* The first character is L, for level.
* The second character indicates the cache level.  The nearest cache is level 1, followed by level 2, and so on.  Level L implies the outermost cache.
* The optional third character indicates whether the cache is limited to instruction opcodes (I) or load/store data (D).

A typical example implementation might include the following caches within the CACHE event hierarchy.

.CACHE Event Caches Example
[[caches-ex]]
[cols="20%,80%"]
|===
| L1D | Level 1 data cache
| L1I | Level 1 instruction cache
| L2 | Level 2 cache
| L3 | Level 3 cache
| LL | Last level cache
|===

NOTE: _The events for the last level cache may be aliased to the events for one of the cache levels listed above it._

NOTE: _An implementation may additionally include other, custom caches within the CACHE event hierarchy, such that the cache name does not conform to the standard convention above._

Like all events in this spec, these CACHE events are per-hart.  For caches that may be shared by multiple harts, the CACHE events should increment only for occurrences directly associated with the local hart.

The second level of the CACHE event hierarchy identifies the access or operation type, as shown in the table below.  Some caches may support only a subset of the defined types.

.CACHE Event Access or Operation Type
[cols="20%,80%"]
|===
| RD | Data reads that lookup the cache.  This includes explicit reads (e.g., the LW instruction) and implicit reads (e.g., page table walks).  
| RD.DATA | The subset of RDs that are data load operations.
| RD.PREF | The subset of RDs that are incoming prefetch reads.
| RD.CODE | The subset of RDs that are code fetch reads.
| WR | Data writes to the cache.  This includes explicit reads (e.g., the SW instruction) and implicit reads (e.g., page accessed/dirty attribute updates).  
| RW | Data reads and writes, the union of the RD and WR types above.
| FILL  | Cache misses or prefetches that result in a line in the cache being filled with data from memory or an outer cache.
| WB | Modified lines written out from the cache to memory or to an outer cache.
| SNOOP | Cache coherency snoops.
| OPREF | Outbound prefetches, for the purpose of pulling lines into the associated cache.
|===

For caches that may be shared by multiple harts, the lookup events (RD*, WR, RW) and SNOOP events should increment only for requests from the local hart.  FILL and WB events should increment only for fills and writebacks resulting from requests from the local hart.  OPREF events should not increment.

Some events in the CACHE event hierarchy include additional levels.  For cache lookup access types (RD*, WR, or RW), a third level counts per lookup result.

.CACHE Event Lookup Results
[cols="20%,80%"]
|===
| ACCESS | Cache lookups
| HIT    | Cache hits
| MISS   | Cache misses
| MERGE  | Lookups that merged with an outstanding lookup
|===

For the RD.DATA and RD.CODE types, there is additionally a MISS.CYCLES event that counts core cycles (at the rate of the Zicntr `cycle` counter) while a load or instruction fetch cache miss, respectively, is outstanding.

The SNOOP type events have two additional levels of hierarchy.

.CACHE Event Snoop Types
[cols="20%,80%"]
|===
| LOCAL  | Snoops from accesses local to the hart
| REMOTE | Snoops from remote harts
|===

If neither the LOCAL or REMOTE modifier is included in the event name, then all snoops are counted.

.CACHE Event Snoop Results
[cols="20%,80%"]
|===
| ACCESS | Snoop lookups
| HIT    | Snoops that hit unmodified data
| HITM   | Snoops that hit modified data
| MISS   | Snoops that miss
|===

An reference example of the full set of CACHE events and metrics, assuming the example set of caches shown above in <<caches-ex>>, is illustrated in the tables below.

include::adoc_event_tables/cache.adoc[]

include::adoc_event_tables/cache_metrics.adoc[]

=== TLB (retirement)

This group contains events and metrics for data and instruction TLB caches (all levels) counted at retirement.

include::adoc_event_tables/tlb_retired.adoc[]

include::adoc_event_tables/tlb_retired_metrics.adoc[]

=== TLB (speculative)

This group contains events and metrics for data and instruction TLB caches (all levels) counted speculatively.

include::adoc_event_tables/tlb_spec.adoc[]

include::adoc_event_tables/tlb_spec_metrics.adoc[]

=== TOP-DOWN

This group contains events and metrics related for Top-down Microarchitecture Analysis (TMA) methodology.

TMA is an industry-standard methodology https://ieeexplore.ieee.org/document/6844459[introduced by Intel] in characterizing the performance of SPEC CPU2006 on Intel CPUs, and since used to characterize https://www.mdpi.com/2078-2489/14/10/554[HPC workloads], https://ieeexplore.ieee.org/abstract/document/9820717[GPU workloads], https://dl.acm.org/doi/10.1145/3369383[microarchitecture changes], https://ieeexplore.ieee.org/abstract/document/9579960[pre-silicon performance validation failures], and more.

TMA allows even developers with minimal microarchitecture knowledge to understand, for a given workload, where bottlenecks reside.  It does so by accounting for the utilization of each pipeline "slot" in the microarchitecture.  As an example, for a 4-wide implementation, there are 4 slots to account for each cycle.  When the hardware is utilized with optimal efficiency, each slot is occupied by an instruction or micro-operation (uop) that will go on to execute and retire.  When bottlenecks occur, due perhaps to a cache miss, branch misprediction, or any number of other microarchitectural conditions, some slots may be either unused or thrown away, which results in inefficiency and reduced performance.  TMA is able to identify these wasted slots, and the stalls, clears, misses, or other events that cause them.  This enables developers to make informed decisions when tuning their code.

TMA accomplishes this by defining a set of hierarchical states into which each slot is categorized.  Each cycle, the frontend of the processor (responsible for instruction fetch and decode) can issue some implementation-defined number (_N_) of instructions/uops to the backend (instruction execution and retire).  Hence there are _N_ issue slots to be categorized per cycle.  At the top level of the TMA hierarchy, issue slots are categorized as described below.

[align="center"]
.Topdown Level 1
image::images/tma-l1.svg[TMA Level 1]

* Frontend Bound - The frontend did not issue a uop to the backend for execution.  Example causes include stalls that result from cache or TLB misses during instruction fetch.
* Backend Bound - The backend could not consume a uop from the frontend.  Example causes include backpressure that results from cache or TLB misses on data (load/store) accesses, or from oversubscribed execution units.
* Bad Speculation - The uop was dropped, as a result of a pipeline clear.  Example clears include branch/jump mispredictions, or memory ordering clears.  This category also includes any pipeline clear recovery cycles during which issue slots go unfilled.
* Retiring - The uop retired.  Ideally the majority of slots fall into this state.

Many of the top-level states listed above include further breakdown at the 2nd and 3rd levels of the TMA hierarchy, as illustrated below.  

[align="center"]
.Topdown Hierarchy
image::images/tma-full.svg[TMA Hierarchy]

[NOTE]
====
_Some imprecision within the event hierarchy is allowed and even expected.  The standard L2 and L3 events may not sum precisely to the parent L1 or L2 events, respectively, as it is expected that there will be some additional sources of bottlenecks beyond those represented by the standard events.  The exception is the Backend Bound L2 events (Core Bound and Memory Bound), which ideally should sum to the Backend Bound event total._

_Because of this possible imprecision, it is recommended that lower level TMA events are examined only when the parent event count or rate is higher than expected.  This avoids spending time on misleading L2 or L3 events that may be implemented by imprecise event formulas rather than precise hardware events._

_Implementations may opt to add custom L2 or L3 events, to identify additional bottlenecks specific to the microarchitecture._
====

The events which follow count slots for each of the states listed above, while the metrics express the slots per state value as a percentage of total slots.

include::adoc_event_tables/topdown.adoc[]

include::adoc_event_tables/topdown_metrics.adoc[]

FIXME: add vector element events/metrics