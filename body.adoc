[[body]]
== Groups

All the events and metrics are split between several groups which are described in details sub-sections below.
In addition most of the groups are further split into 2 variants:

* RET - for non-speculative events counted at retirement. For example, INST.RET counts retired instructions.
* SPEC - for speculative events. For example, INST.SPEC counts instructions that are issued to the backend pipeline, regardless of whether they retire.

NOTE: _In general, RET events are more useful for performance analysis, since they are consistent with software's view of the instruction flow. But they can be significantly more expensive to implement, as they require event data to be staged along with the associated instruction to retirement. It is up to implementations to decide whether to support the RET, SPEC, or both variants of an event._

=== GENERAL

This group contains general events not specific to a particular part of CPU pipeline. 

include::adoc_event_tables/general.adoc[]

=== CTRL_FLOW (retirement)

Retirement control flow group which contains events and metrics for counting all control transfer instructions, or just those that were mispredicted, including breakdowns by transfer type.

include::adoc_event_tables/prediction_retired.adoc[]

include::adoc_event_tables/prediction_metrics.adoc[]

=== CACHE
:xrefstyle: short

This group contains events and metrics for instruction, data, and unified caches.  Events in this group count accesses from the cache's perspective; if an instruction performs two cache accesses, they will be counted separately.  Further, all events in this group count speculative accesses.

The top level of the CACHE event hierarchy idenfies the cache associated with the event.  The standard cache naming scheme is detailed below.

* The first character is L, for level.
* The second character indicates the cache level.  The nearest cache is level 1, followed by level 2, and so on.  Level L implies the outermost cache.
* The optional third character indicates whether the cache is limited to instruction opcodes (I) or load/store data (D).

A typical example implementation might include the following caches within the CACHE event hierarchy.

.CACHE Event Caches Example
[[caches-ex]]
[cols="20%,80%"]
|===
| L1D | Level 1 data cache
| L1I | Level 1 instruction cache
| L2 | Level 2 cache
| L3 | Level 3 cache
| LL | Last level cache
|===

NOTE: The events for the last level cache may be aliased to the events for one of the cache levels listed above it.

An implementation may additionally include other, custom caches within the CACHE event hierarchy.

Like all events in this spec, these CACHE events are per-hart.  For caches that may be shared by multiple harts, the CACHE events should increment only for occurrences directly associated with the local hart.

The second level of the CACHE event hierarchy identifies the access or operation type, as shown in the table below.  Some caches may support only a subset of the defined types.

.CACHE Event Access or Operation Type
[cols="20%,80%"]
|===
| RD | Data reads that lookup the cache.  This includes explicit reads (e.g., the LW instruction) and implicit reads (e.g., page table walks).  
| RD.DATA | The subset of RDs that are data load operations.
| RD.PREF | The subset of RDs that are incoming prefetch reads.
| RD.CODE | The subset of RDs that are code fetch reads.
| WR | Data writes to the cache.  This includes explicit reads (e.g., the SW instruction) and implicit reads (e.g., page accessed/dirty attribute updates).  
| RW | Data reads and writes, the union of the RD and WR types above.
| FILL  | Cache misses or prefetches that result in a line in the cache being filled with data from memory or an outer cache.
| WB | Modified lines written out from the cache to memory or to an outer cache.
| SNOOP | Cache coherency snoops.
| OPREF | Outbound prefetches, for the purpose of pulling lines into the associated cache.
|===

For caches that may be shared by multiple harts, the request events (RD, WR, RW) and SNOOP events should increment only for requests from the local hart.  FILL and WB events should increment only for fills and writebacks resulting from requests from the local hart.  OPREF events should not increment.

Some events in the CACHE event hierarchy include additional levels.  For cache lookup access types (RD*, WR, or RW), a third level counts per lookup result.

.CACHE Event Lookup Results
[cols="20%,80%"]
|===
| ACCESS | Cache lookups
| HIT    | Cache hits
| MISS   | Cache misses
| MERGE  | Lookups that merged with an outstanding lookup
|===

For the RD.DATA type, there is additionally a MISS.CYCLES event that counts core cycles (at the rate of the Zicntr `cycle` counter) while a load miss is outstanding.

The SNOOP type events have two additional levels of hierarchy.

.CACHE Event Snoop Types
[cols="20%,80%"]
|===
| LOCAL  | Snoops from accesses local to the hart
| REMOTE | Snoops from remote harts
|===

If neither the LOCAL or REMOTE modifier is included in the event name, then all snoops are counted.

.CACHE Event Snoop Results
[cols="20%,80%"]
|===
| ACCESS | Snoop lookups
| HIT    | Snoops that hit unmodified data
| HITM   | Snoops that hit modified data
| MISS   | Snoops that miss
|===

An reference example of the full set of CACHE events and metrics, assuming the example set of caches shown above in <<caches-ex>>, is illustrated in the tables below.

include::adoc_event_tables/cache.adoc[]

include::adoc_event_tables/cache_metrics.adoc[]

=== TLB (retirement)

This group contains events and metrics for data and instruction TLB caches (all levels) counted at retirement.

include::adoc_event_tables/tlb_retired.adoc[]

include::adoc_event_tables/tlb_retired_metrics.adoc[]

=== TLB (speculative)

This group contains events and metrics for data and instruction TLB caches (all levels) counted speculatively.

include::adoc_event_tables/tlb_spec.adoc[]

include::adoc_event_tables/tlb_spec_metrics.adoc[]

=== TOP-DOWN

This group contains events and metrics related for Top-down Microarchitecture Analysis (TMA) methodology.

TMA is an industry-standard methodology https://ieeexplore.ieee.org/document/6844459[introduced by Intel] in characterizing the performance of SPEC CPU2006 on Intel CPUs, and since used to characterize https://www.mdpi.com/2078-2489/14/10/554[HPC workloads], https://ieeexplore.ieee.org/abstract/document/9820717[GPU workloads], https://dl.acm.org/doi/10.1145/3369383[microarchitecture changes], https://ieeexplore.ieee.org/abstract/document/9579960[pre-silicon performance validation failures], and more.

TMA allows even developers with minimal microarchitecture knowledge to understand, for a given workload, where bottlenecks reside.  It does so by accounting for the utilization of each pipeline "slot" in the microarchitecture.  As an example, for a 4-wide implementation, there are 4 slots to account for each cycle.  When the hardware is utilized with optimal efficiency, each slot is occupied by an instruction or micro-operation (uop) that will go on to execute and retire.  When bottlenecks occur, due perhaps to a cache miss, branch misprediction, or any number of other microarchitectural conditions, some slots may be either unused or thrown away, which results in inefficiency and reduced performance.  TMA is able to identify these wasted slots, and the stalls, clears, misses, or other events that cause them.  This enables developers to make informed decisions when tuning their code.

TMA accomplishes this by defining a set of hierarchical states into which each slot is categorized.  Each cycle, the frontend of the processor (responsible for instruction fetch and decode) can issue some implementation-defined number (_N_) of instructions/uops to the backend (instruction execution and retire).  Hence there are _N_ issue slots to be categorized per cycle.  At the top level of the TMA hierarchy, issue slots are categorized as described below.

[align="center"]
.Topdown Level 1
image::images/tma-l1.svg[TMA Level 1]

* Frontend Bound - The frontend did not issue a uop to the backend for execution.  Example causes include stalls that result from cache or TLB misses during instruction fetch.
* Backend Bound - The backend could not consume a uop from the frontend.  Example causes include backpressure that results from cache or TLB misses on data (load/store) accesses, or from oversubscribed execution units.
* Bad Speculation - The uop was dropped, as a result of a pipeline clear.  Example clears include branch/jump mispredictions, or memory ordering clears.  This category also includes any pipeline clear recovery cycles during which issue slots go unfilled.
* Retiring - The uop retired.  Ideally the majority of slots fall into this state.

Many of the top-level states listed above include further breakdown at the 2nd and 3rd levels of the TMA hierarchy, as illustrated below.  

[align="center"]
.Topdown Hierarchy
image::images/tma-full.svg[TMA Hierarchy]

[NOTE]
====
_Some imprecision within the event hierarchy is allowed and even expected.  The standard L2 and L3 events may not sum precisely to the parent L1 or L2 events, respectively, as it is expected that there will be some additional sources of bottlenecks beyond those represented by the standard events.  The exception is the Backend Bound L2 events (Core Bound and Memory Bound), which ideally should sum to the Backend Bound event total._

_Because of this possible imprecision, it is recommended that lower level TMA events are examined only when the parent event count or rate is higher than expected.  This avoids spending time on misleading L2 or L3 events that may be implemented by imprecise event formulas rather than precise hardware events._

_Implementations may opt to add custom L2 or L3 events, to identify additional bottlenecks specific to the microarchitecture._
====

The events which follow count slots for each of the states listed above, while the metrics express the slots per state value as a percentage of total slots.

include::adoc_event_tables/topdown.adoc[]

include::adoc_event_tables/topdown_metrics.adoc[]

=== RVV (retirement)

This group contains events and metrics related to vectorized operations counted at retirement.

include::adoc_event_tables/rvv_retired.adoc[]

include::adoc_event_tables/rvv_retired_metrics.adoc[]

=== RVV (speculative)

This group contains events and metrics related to vectorized operations counted speculatively.

include::adoc_event_tables/rvv_spec.adoc[]

include::adoc_event_tables/rvv_spec_metrics.adoc[]
